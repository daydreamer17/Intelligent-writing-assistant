# ============================================================================
# HelloAgents Áªü‰∏ÄÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆÊñá‰ª∂
# ============================================================================
# Â§çÂà∂Ê≠§Êñá‰ª∂‰∏∫ .env Âπ∂Â°´ÂÖ•‰Ω†ÁöÑAPIÂØÜÈí•
# Á≥ªÁªüË¶ÅÊ±ÇÔºöPython 3.10+ ÔºàÂøÖÈúÄÔºâ

# ============================================================================
# üöÄ Áªü‰∏ÄÈÖçÁΩÆÊ†ºÂºèÔºàÊé®ËçêÔºâ- Ê°ÜÊû∂Ëá™Âä®Ê£ÄÊµãprovider
# ============================================================================
# Âè™ÈúÄÈÖçÁΩÆ‰ª•‰∏ã4‰∏™ÈÄöÁî®ÁéØÂ¢ÉÂèòÈáè,Ê°ÜÊû∂‰ºöËá™Âä®ËØÜÂà´LLMÊèê‰æõÂïÜÔºö

LLM_PROVIDER=openai
LLM_MODEL=YOUR_MODEL_NAME
LLM_API_KEY=YOUR_API_KEY
LLM_API_BASE=YOUR_URL
LLM_TIMEOUT=300
LLM_MAX_TOKENS=1200
LLM_RETRY_MAX=5
LLM_RETRY_BACKOFF=10
LLM_COOLDOWN_SECONDS=2
LLM_CLEAR_SESSION_ON_OVERFLOW=true
LLM_MAX_INPUT_CHARS=12000
LLM_MAX_CONTEXT_TOKENS=32768
LLM_INPUT_SAFETY_MARGIN=8000
LLM_CHARS_PER_TOKEN=0.6
LLM_HISTORY_MAX_CHARS=8000
LLM_SESSION_MAX_HISTORY_MESSAGES=80
LLM_SESSION_MAX_HISTORY_CHARS=12000
LLM_MEMORY_MAX_PIN_RATIO=0.35
LLM_CONTEXT_COMPRESS_ENABLED=true
LLM_CONTEXT_COMPRESS_THRESHOLD=0.85
LLM_CONTEXT_COMPRESS_TARGET=0.5
LLM_CONTEXT_COMPRESS_KEEP_LAST=4
LLM_CONTEXT_COMPRESS_MAX_TOKENS=600
LLM_CONTEXT_COMPRESS_INPUT_CHARS=12000
LLM_CONTEXT_COMPRESS_MERGE_THRESHOLD=0.6
LLM_CONTEXT_COMPRESS_MERGE_TARGET=0.35
LLM_LAYERED_LONG_RATIO=0.35
LLM_LAYERED_RECENT_RATIO=0.25
LLM_LAYERED_TAIL_RATIO=0.4
# Guard against MCP-expanded tool descriptions exploding system prompt tokens.
LLM_TOOL_PROMPT_MAX_TOKENS=4000
LLM_TOOL_PROMPT_CONTEXT_RATIO=0.8
# Enable only if you truly need agent-side function/tool calling in normal writing flow.
LLM_AGENT_TOOL_CALLING_ENABLED=false
LLM_MEMORY_TAG_PIN=[MEM:PIN]
LLM_MEMORY_TAG_COMPRESS=[MEM:COMPRESS]
LLM_MEMORY_TAG_DEFER=[MEM:DEFER]
LLM_MEMORY_TAG_FORGET=[MEM:FORGET]
LLM_MEMORY_META_PRIORITY=true
LLM_MEMORY_AUTO_POLICY_ENABLED=true
LLM_MEMORY_MIN_CHARS=16
LLM_MEMORY_PIN_THRESHOLD=0.82
LLM_MEMORY_COMPRESS_THRESHOLD=0.56
LLM_MEMORY_DEFER_THRESHOLD=0.30
LLM_MEMORY_RECENCY_WEIGHT=0.4
LLM_MEMORY_ROLE_WEIGHT=0.2
LLM_MEMORY_LENGTH_WEIGHT=0.1
LLM_MEMORY_KEYWORD_WEIGHT=0.3
LLM_MEMORY_LENGTH_BASE=1200
LLM_MEMORY_KEYWORD_HITS_BASE=3
LLM_MEMORY_IMPORTANT_KEYWORDS=constraint,requirements,must,style,format,citation,source,topic,goal,‰∏çË¶Å,ÂøÖÈ°ª,Á∫¶Êùü,È£éÊ†º,ÂºïÁî®,ÁõÆÊ†á
LLM_MEMORY_LOG_VERBOSE=true
LLM_COLD_STORE_ENABLED=true
LLM_COLD_STORE_PATH=data/app.db
LLM_COLD_STORE_MAX_CHARS=5000
LLM_COLD_RECALL_ENABLED=true
LLM_COLD_RECALL_TOP_K=3
LLM_COLD_RECALL_MAX_CHARS=300
LLM_COLD_RECALL_LOOKBACK=200
LLM_SESSION_MAX_AGENTS=32
LLM_SESSION_TTL_SECONDS=3600
STAGE_PLAN_MAX_TOKENS=2000
STAGE_PLAN_MAX_INPUT_CHARS=8000
STAGE_DRAFT_MAX_TOKENS=6000
STAGE_DRAFT_MAX_INPUT_CHARS=12000
STAGE_REVIEW_MAX_TOKENS=4000
STAGE_REVIEW_MAX_INPUT_CHARS=10000
STAGE_REWRITE_MAX_TOKENS=6000
STAGE_REWRITE_MAX_INPUT_CHARS=12000
PIPELINE_PLAN_MAX_TOKENS=2000
PIPELINE_PLAN_MAX_INPUT_CHARS=8000
PIPELINE_DRAFT_MAX_TOKENS=6000
PIPELINE_DRAFT_MAX_INPUT_CHARS=12000
PIPELINE_REVIEW_MAX_TOKENS=4000
PIPELINE_REVIEW_MAX_INPUT_CHARS=10000
PIPELINE_REWRITE_MAX_TOKENS=6000
PIPELINE_REWRITE_MAX_INPUT_CHARS=12000
PIPELINE_STAGE_SLEEP=3
PIPELINE_EFFECTIVE_OUTPUT_MIN_CHARS=200
RAG_HYDE_ENABLED=false
RAG_QUERY_MAX_CHARS=800
RAG_HYDE_MAX_CHARS=1500
RAG_HYDE_MAX_TOKENS=400
RAG_MAX_EXPANSION_QUERIES=3
RAG_RERANK_ENABLED=false
RAG_RERANK_TOP_K=5
RAG_RERANK_MAX_CANDIDATES=15
RAG_RERANK_SNIPPET_CHARS=600
RAG_RERANK_MAX_PROMPT_CHARS=6000
RAG_RERANK_MAX_TOKENS=300
RAG_DYNAMIC_TOPK_ENABLED=true
RAG_DYNAMIC_SMALL_THRESHOLD=50
RAG_DYNAMIC_LARGE_THRESHOLD=500
RAG_DYNAMIC_TOPK_SMALL=5
RAG_DYNAMIC_TOPK_MEDIUM=10
RAG_DYNAMIC_TOPK_LARGE=12
RAG_DYNAMIC_CANDIDATES_SMALL=15
RAG_DYNAMIC_CANDIDATES_MEDIUM=24
RAG_DYNAMIC_CANDIDATES_LARGE=36
RAG_NOTES_DYNAMIC_ENABLED=true
RAG_NOTES_TOP_K=7
RAG_NOTES_SMALL_THRESHOLD=10
RAG_NOTES_LARGE_THRESHOLD=100
RAG_NOTES_TOP_K_SMALL=5
RAG_NOTES_TOP_K_MEDIUM=8
RAG_NOTES_TOP_K_LARGE=12
RAG_NOTES_INJECTION_MAX_ITEMS=8
RAG_NOTES_INJECTION_MAX_CHARS=4000
RAG_NOTES_INJECTION_MIN_CHARS=120
RAG_NOTES_INJECTION_MIN_SCORE=0.03
RAG_COVERAGE_THRESHOLD=0.3
RAG_COVERAGE_SEMANTIC_ENABLED=false
RAG_COVERAGE_SEMANTIC_THRESHOLD=0.25
RAG_COVERAGE_SEMANTIC_MAX_PARAGRAPHS=20
RAG_COVERAGE_SEMANTIC_MAX_NOTES=12
RAG_COVERAGE_SEMANTIC_BATCH_SIZE=8
RAG_COVERAGE_SEMANTIC_MAX_TEXT_CHARS=2000
RAG_REFUSAL_ENABLED=true
RAG_REFUSAL_MODE=fallback
RAG_REFUSAL_MIN_QUERY_TERMS=2
RAG_REFUSAL_MIN_DOCS=1
RAG_REFUSAL_MIN_RECALL=0.1
RAG_REFUSAL_MIN_AVG_RECALL=0.05
RAG_REFUSAL_FALLBACK_TOP_K=12
RAG_REFUSAL_FALLBACK_MIN_DOCS=2
RAG_REFUSAL_FALLBACK_MIN_RECALL=0.12
RAG_REFUSAL_FALLBACK_MIN_AVG_RECALL=0.06
RAG_CITATION_ENFORCE=false
RAG_CITATION_REQUIRE_ALL_LABELS=true
RAG_CITATION_APPEND_MISSING_TO_TAIL=true
RAG_CITATION_TAIL_PREFIX=ÂºïÁî®Ë°•ÂÖ®
RAG_CITATION_TOP_K=5
RAG_EVIDENCE_MAX_ITEMS=12
RAG_EVIDENCE_MAX_CHARS=4000
RAG_EVIDENCE_MAX_TOKENS=400
MCP_GITHUB_ENABLED=false
# Max number of expanded GitHub MCP tools to register (0 means unlimited).
MCP_GITHUB_MAX_TOOLS=5
GITHUB_PERSONAL_ACCESS_TOKEN=YOUR_GITHUB_TOKEN
STORAGE_PATH=data/app.db
# Preferred retrieval switch:
# - sqlite_only: use SQLite keyword retrieval only
# - hybrid: SQLite + Qdrant vector retrieval (if Qdrant is configured)
RETRIEVAL_MODE=sqlite_only
# Conversation memory switch:
# - session: isolate memory by session_id (recommended)
# - global: share one global in-memory history
CONVERSATION_MEMORY_MODE=session
# Legacy compatibility flag (derived automatically when RETRIEVAL_MODE is set):
MEMORY_MODE=short_term
QDRANT_URL=YOUR_URL
QDRANT_API_KEY=YOUR_API_KEY
QDRANT_COLLECTION=hello_agents_vectors
QDRANT_EMBED_DIM=1024
QDRANT_DISTANCE=cosine
QDRANT_TIMEOUT=30
EMBEDDING_PROVIDER=openai_compatible
EMBEDDING_MODEL=YOUR_MODEL_NAME
EMBEDDING_API_KEY=YOUR_API_KEY
EMBEDDING_API_BASE=YOUR_URL
EMBEDDING_TIMEOUT=20
UPLOAD_MAX_MB=10
UVICORN_RELOAD=false
